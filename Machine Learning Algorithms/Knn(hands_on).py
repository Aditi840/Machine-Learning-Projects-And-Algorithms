# -*- coding: utf-8 -*-
"""knn2(hands on).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Bx1CL_9Vqdu0fd_ImuezRJOecVpsOF9G
"""

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from mlxtend.plotting import plot_decision_regions
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split

#Input :  k and data
#Output : The graph of the decision boundary
def knn_comparison(data, k): #k and the data are input to the function
  x = data[['X','Y']].values # independent features
  y = data['class'].astype(int).values # y -> target/true labels
  x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.3)

  from sklearn.preprocessing import StandardScaler
  scaler = StandardScaler()
  x_train = scaler.fit_transform(x_train)
  x_test = scaler.transform(x_test)

  knn = KNeighborsClassifier(n_neighbors=k) #it will initialise the model with @neighbours as k
  knn.fit(x_train, y_train) # train the model
  print("Train Accuracy : ", knn.score(x_train,y_train)) # test the model and it computes the accuracy (train data accuracy)
  print("Val Accuracy : ", np.mean(cross_val_score(knn, x_train, y_train, cv=10)))
  # Plotting decision region
  plot_decision_regions(x_train, y_train, clf = knn, legend=2) # it plots the decision boundary
  ##Adding axes annotations
  plt.xlabel('X') #Names the x-axis
  plt.ylabel('Y') #Names the y-axis
  plt.title('Knn with K='+ str(k)) #Names the graph
  plt.show() #Displays the graph


def knn_no_plot(data, k): #k and data are inputs to the function
  x = data[['X','Y']].values #independent features
  y = data['class'].astype(int).values # y true/target variable
  clf = KNeighborsClassifier(n_neighbors = k) #it will initialize the model with neighbors as k
  clf.fit(x, y) #train the model
  print("K : ", k, " Train Accuracy : ",clf.score(x,y), " Val Accuracy : ", np.mean(cross_val_score(clf, x, y, cv = 5))) #test the model and it computes the accuracy train data accuracy
  #plotting decision region
  plot_decision_regions(x, y, clf=clf, legend = 2) #it plots the decision boundary
  plt.xlabel('X') #Name the x-axis
  plt.ylabel('Y') #Name the y-axis
  plt.title('Knn with K=' + str(k)) #Names the graph
  plt.show() #displays the graph


def logistic(data, k=0):
  x = data[['X','Y']].values
  y = data['class'].astype(int).values
  clf = LogisticRegression()
  clf.fit(x,y)
  print(clf.score(x,y))
  print("Train Accuracy : ", clf.score(x,y)) #test the model and computes the accuracy train data accuracy
  print("Val Accuracy : ", np.mean(cross_val_score(clf, x, y, cv = 5)))
  #plotting decision region
  plot_decision_regions(x, y, clf=clf, legend = 2)
  plt.xlabel('X')
  plt.ylabel('Y')
  plt.title('Logistic Regression decision boundary')
  plt.show()

data1 = pd.read_csv('/ushape.csv')
for i in [1,2,3,4,5,20,30,40,60]: #Hit n trail
  print(i)
  knn_no_plot(data1,i)

data2 = pd.read_csv('/concertriccir2.csv')
for i in [1,2,3,4,5,20,30,40,60]:
  knn_comparison(data2, i)

data1 = pd.read_csv('/concertriccir2.csv')
for i in [1,2,3,4,5,20,30,40,60]:
  knn_no_plot(data1, i)

data3 = pd.read_csv('/xor.csv')
for i in [1,2,3,4,5,20,30,40,60]:
  knn_no_plot(data3, i)

data4 = pd.read_csv('/linearsep.csv')
for i in [1,2,3,4,5,20,30,40,60]:
  knn_no_plot(data4, i)

"""Visualizing the logistic regression boundary"""

logistic(data4,1)

logistic(data3,1)